{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "-IndividualFeedback_CML2_Project2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Extended Project Grading\n",
        "\n",
        "| Criteria | Weighting (%) | Score | Justification | Improvements  |\n",
        "|----------|---------------|-------|---------------|---------------|\n",
        "|Code runs | 5           |   5   |               |               |\n",
        "|Data preparation |\t10 | 10 | Good data preprocessing and visualisation, largely carried forward from previous project but well extended to LOS response  \n",
        "|DT method(s) have been used  | 10 | 10 | Decision trees, Random Forests,  AdaBoost, GBM and XGBoost \n",
        "|Hyperparameter optimization | 10 | 10 | All trained over GridSearch with the help of BayesSearchCV and skopt\n",
        "|Ensemble method(s) have been used | 10 | 10 | \n",
        "|Complexity of ensemble used | 10 | 5 | Stacking considered but features not propagated from the base learners to the meta learner \n",
        "|Variety of weak learners used  | 5 | 5 | kNN and linear models considered as well as DTs\n",
        "|Length of stay is predicted for each test patient | 5 | 5 |\n",
        "|Accuracy itself | 10 | 1 |\n",
        "|Attempts made to interpret predictions | 5 | 5 | Decision tree feature Importance, LIME and SHAP considered \n",
        "|Neat and understandable code| 5 | 5 | Excellent presentation of work \n",
        "|Improved Methods from class| 10 | 4 |  BayessearchCV and skopt, plus bonus for excellent presentation\n",
        "|Neural Networks have been attempted| 5 | 5 | MLP implemented in sklearn   \n",
        "\n",
        "Score: 80\n",
        "\n",
        "Feedback: Excellent work. Good data preprocessing and visualisation, largely carried forward from the previous assignment but well extended to LOS response. Good implementations of decision tree methods seen in class, including how these can be trained using GridSearch and interpreted using SHAP. Good implementation of stacking although i would have liked to see you investigate propagating the features from the base learners to the meta learners. Good attempt to implement Neural Networks in sklearn."
      ],
      "metadata": {
        "id": "iHemZ7sob1zB"
      }
    }
  ]
}